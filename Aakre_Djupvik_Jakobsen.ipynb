{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biophysics project - Monte Carlo simulation of polymer folding\n",
    "\n",
    "Date: 06.02.2024\n",
    "\n",
    "Authors: Vemund Aakre, Thorbj√∏rn Djupvik and Oskar Feed Jakobsen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Chains of amino acids are the the building blocks of proteins.\n",
    "These will fold themeselves in the three dimensional space, and thus, chemical bonding between non-neighbouring parts of the chain will occur.\n",
    "The generalization of such three-dimensional structures are called *polymers*. A polymer consists of repeating units called *monomers*.\n",
    "In this project, we will simulate polymer folding in two dimension.\n",
    "By using methods of Monte Carlo simulation we will investigate physical properties of polymers.\n",
    "The energy and the spacial extent of the structures, in addition to how these depend on temperature, are quantities that we will take a closer look at.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import time\n",
    "from numba import njit\n",
    "from scipy.constants import Boltzmann\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The representation of a polymer\n",
    "To represent a two dimensional polymer, one may try to create a two dimensional matrix to represent 2D space\n",
    "and denote with for example 1 or 0 whether a monomer is located at a point in space or not. This will in general be \n",
    "unsuitable when scaling the problem, since the size of the matrix scales as $N^2$ with the size of the polymer. This also \n",
    "results in a higher computation time, because every computation done with the polymer requires iterating through the entire \n",
    "matrix. As most of the indices will be zero, this is a waste of space and time, and can be optimized.\n",
    "\n",
    "A more efficient way of representing the polymer is just to store its monomer coordinates in a $N\\times2$ matrix, reducing \n",
    "the matrix size to scale linearly with the size of the polymer. In our implementation the matrix has a size of $N\\times2$, \n",
    "where each row contains the coordinate of a single monomer, $(x, y)$. The order of the rows is set to be the order\n",
    "in which they appear in the polymer. For a polymer of size N, the structure would look like this:\n",
    "\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "   x_1& y_1\\\\\n",
    "   x_2& y_2\\\\\n",
    "   \\vdots&\\vdots \\\\\n",
    "   x_N& y_N\\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### A couple of conventions\n",
    "Following the naming convention of the project description, we will name the first monomer 'monomer 1', and not by its index \n",
    "in the matrix. We will also define the head of a polymer with respect to a given monomer $i$, to be all monomers $j$\n",
    "where $j<i$. The tail is defined identically for $j>i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymers in action\n",
    "To be able to work with polymers in the code, it is nice to have a function to automatically create a polymer of a given size \n",
    "without having to manually type it into the code.\n",
    "The function `generate_flat_polymer` generates a flat polymer of a given length centered around the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def generate_flat_polymer(\n",
    "    polymer_length: int, mid_of_polymer: np.ndarray = np.zeros(2)\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Generates a horizontal polymer with N (polymer_length) monomers\n",
    "\n",
    "    Args:\n",
    "        polymer_length (int): Number of monomers\n",
    "        mid_of_polymer (np.ndarray, optional): The coordinates of the center monomer. Defaults to np.zeros(2).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: the generated polymer\n",
    "    \"\"\"\n",
    "    polymer_array = np.zeros((polymer_length, 2), dtype=np.int32)\n",
    "    polymer_start = -int(polymer_length / 2) + mid_of_polymer[0]\n",
    "    # + 1/2 to handle even numbers\n",
    "    polymer_end = int((polymer_length + 1) / 2) + mid_of_polymer[0]\n",
    "    polymer_array[:, 1] = mid_of_polymer[1]\n",
    "    polymer_array[:, 0] = np.arange(polymer_start, polymer_end, 1, dtype=np.int32)\n",
    "\n",
    "    return polymer_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is beneficial to be able to visualize the polymers whilst working with them. This helps debugging the code and analyzing the problems at hand.\n",
    "The function `illustrate_polymer` displays the polymer in a grid of size $N\\times N$ with a color gradient to separate the \n",
    "monomers from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_polymer(\n",
    "    ax,\n",
    "    polymer: np.ndarray,\n",
    "    cmap: str = \"Greens\",\n",
    "    numbers: bool = False,\n",
    "    title: str = \"\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Uses matplotlib.pyplot.pcolormesh to illustrate a polymer.\n",
    "\n",
    "    Args:\n",
    "        ax: Axes to plot on\n",
    "        polymer: Nx2-dimensional array containing coordinates for the N monomers\n",
    "        cmap: matplotlib colormap\n",
    "        number: Defaults to False. If True the monomers will display their index\n",
    "        title: Title\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Make a NxN-grid\n",
    "    N = len(polymer)\n",
    "    x = y = np.arange(N + 1)\n",
    "    Z = np.zeros((N, N))\n",
    "\n",
    "    # Placing the polymer on the grid such that the middle monomer is in the center.\n",
    "    middle_monomer = polymer[int(N / 2)]\n",
    "    for i, monomer in enumerate(polymer):\n",
    "        # Shifting by 1 if N is even and middle monomer has negative coordinates\n",
    "        shifty = (1 if N % 2 == 0 and middle_monomer[1] < 0 else 0)\n",
    "        shiftx = (1 if N % 2 == 0 and middle_monomer[0] < 0 else 0)\n",
    "        x_coord = monomer[1] + int(N / 2) - middle_monomer[1] - shifty\n",
    "        y_coord = monomer[0] + int(N / 2) - middle_monomer[0] - shiftx\n",
    "        Z[x_coord, y_coord] = i + 2\n",
    "        if numbers:\n",
    "            ax.text(y_coord + 0.5, x_coord + 0.5, i + 1, size=\"x-large\", color='red')\n",
    "\n",
    "    ax.pcolormesh(x, y, Z, shading=\"flat\", cmap=cmap)\n",
    "    ax.set(title=title, xticks=x, xticklabels=[], yticks=y, yticklabels=[])\n",
    "    ax.tick_params(axis=\"both\", left=False, right=False, bottom=False, top=False)\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use `illustrate_polymer` to get a sense of how a flat polymer consisting of 10 monomers looks like. The numbers $1$ through $10$ walks the polymer from it's head to it's tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymer = generate_flat_polymer(polymer_length=10)\n",
    "fig, ax = plt.subplots()\n",
    "illustrate_polymer(ax, polymer, numbers=True, cmap=\"Greens\", title=\"Polymer consisting of $10$ monomers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the project description, our model is a simplified 2D-model of polymers, and the polymers are therefore subject to \n",
    "certain restrictions. A polymer of size $N$ is only considered *intact* if it satisfies the following rules:\n",
    "\n",
    "1. It has $N$ monomers.\n",
    "2. Each monomer is represented by a unique integer $m \\in [1, N]$. This means that no monomer is represented by the same number as another monomer.\n",
    "3. A monomer represented by the integer $m$ is the closest neighbour to the monomers represented by the integers $m-1$ and $m+1$. Monomers at the ends, $m=1$ and $m=N$ , need only to be closest neighbour to $m=2$ and $m=N-1$ respectivly. Two monomers are closest neighbours if the distance between them is exactly equal to one.\n",
    "4. Two monomers do not occupy the same space simultaneously. \n",
    "\n",
    "Thus, when trying to fold a polymer, we always have to check its validity before attempting to operate on it. The functions \n",
    "defined underneath all implements the validation-logic. An important thing to note is that the validation function needs to \n",
    "be fast. When running the simulation, it might get called multiple times for every Monte-Carlo step. This means that the time \n",
    "the program spends in this function accumulates quickly to a considerable size when running the simulation functions we will \n",
    "define in a later section.\n",
    "Here are three different implementations, ordered by the time of writing, where we have tried to optimize the time spent.\n",
    "\n",
    "The first one is a for-loop implementation. It has the benefit of an early return if the polymer is not intact when checking \n",
    "the distances between neighbouring monomers. Method 2 \n",
    "on the other hand will always run the worst case scenario and check all the distances before returning. However it is,\n",
    "completely implemented with *NumPy* functions, and for that reason it is actually faster as we will see in the [Benchmarks](#Benchmarks) \n",
    "section. The last implementation uses *Numba* to \n",
    "Just-In-Time compile the function, also known as JIT-compiling. Because *Numba* does not support np.unique with axis specified, we had to rewrite that part to python \n",
    "for-loops. Here we could again utilize the early return optimization, but now when checking for overlap in the polymer.\n",
    "\n",
    "We \n",
    "will return to the details of these implementations when we discuss the time usage in the [Benchmarks](#Benchmarks) section, but for now \n",
    "it can \n",
    "be said that `check_if_intact` is the fastest of them, and the one we will use.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_intact_1(polymer: np.ndarray, polymer_length: int) -> bool:\n",
    "    \"\"\"Checks if polymer is intact\n",
    "\n",
    "    Args:\n",
    "        polymer (np.ndarray): The polymer to check\n",
    "        polymer_length (int): Length of the polymer\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the polymer is intact\n",
    "    \"\"\"\n",
    "    # Checks that the polymer has N monomers, where each has a unique whole number representation\n",
    "    if np.size(np.unique(polymer, axis=0), axis=0) != polymer_length:\n",
    "        return False\n",
    "\n",
    "    for i in range(1, polymer_length):\n",
    "        # Don't have to take the square root (faster), as any value different from 1 indicates a broken polymer anyway.\n",
    "        distance = (polymer[i - 1, 0] - polymer[i, 0]) ** 2 + (\n",
    "            polymer[i - 1, 1] - polymer[i, 1]\n",
    "        ) ** 2\n",
    "        if distance != 1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_intact_2(polymer: np.ndarray, polymer_length: int) -> bool:\n",
    "    \"\"\"Checks if polymer is intact\n",
    "\n",
    "    Args:\n",
    "        polymer (np.ndarray): The polymer to check\n",
    "        polymer_length (int): Length of the polymer\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the polymer is intact\n",
    "    \"\"\"\n",
    "    # Checks that the polymer has N monomers, where each has a unique whole number representation\n",
    "    if np.size(np.unique(polymer, axis=0), axis=0) != polymer_length:\n",
    "        return False\n",
    "\n",
    "    test = polymer[1:]\n",
    "    test_mot = polymer[:-1]\n",
    "    # Don't have to take the square root or square (faster), as any value different from 1 indicates a broken polymer anyway.\n",
    "    distance_array = np.abs(test[:, 0] - test_mot[:, 0]) + np.abs(\n",
    "        test[:, 1] - test_mot[:, 1]\n",
    "    )\n",
    "    if np.any(distance_array != 1):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def check_if_intact(polymer: np.ndarray, polymer_length: int) -> bool:\n",
    "    \"\"\"Checks if polymer is intact\n",
    "\n",
    "    Args:\n",
    "        polymer (np.ndarray): polymer that is checked\n",
    "        polymer_length (int): length of the polymer\n",
    "\n",
    "    Returns:\n",
    "        bool: True if polymer is intact\n",
    "    \"\"\"\n",
    "\n",
    "    if len(polymer) != polymer_length:\n",
    "        return False\n",
    "\n",
    "    unique_monomer = np.zeros_like(polymer)\n",
    "    # First monomer is always unique\n",
    "    unique_monomer[0] = polymer[0]\n",
    "\n",
    "    # Does not have to check the first monomer\n",
    "    for i in range(1, polymer_length):\n",
    "        for j in range(i):\n",
    "            # checks that the monomer's coordinates are not similar to a previous monomer\n",
    "            if (\n",
    "                polymer[i, 0] == unique_monomer[j, 0]\n",
    "                and polymer[i, 1] == unique_monomer[j, 1]\n",
    "            ):\n",
    "                return False\n",
    "            else:\n",
    "                unique_monomer[i] = polymer[i]\n",
    "\n",
    "    test = polymer[1:]\n",
    "    test_against = polymer[:-1]\n",
    "    # Don't need squareroot since all other values than 1 means that it is not intact\n",
    "    distance_array = (test[:, 0] - test_against[:, 0]) ** 2 + (\n",
    "        test[:, 1] - test_against[:, 1]\n",
    "    ) ** 2\n",
    "\n",
    "    # If distance-array contains anything other than 1, the polymer is not intact\n",
    "    if np.any(distance_array != 1):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation\n",
    "\n",
    "To rotate a polymer around a given monomer, we only need to look at the relative position between the rotation center and the \n",
    "monomers which are to be rotated. Let's denote the coordinates of the rotation center as $(x_s, y_s)$, and of an arbitrary \n",
    "monomer as $(x_0, y_0)$. Then the relative position of the monomer with respect to the rotation center is given by\n",
    "$$\n",
    "    (x_{0, \\text{rel}}, y_{0, \\text{rel}}) = (x_0-x_s, y_0-y_s).\n",
    "$$\n",
    "When the monomer is rotated, the new relative coordinates in terms of the old ones is\n",
    "$$\n",
    "    (x_{1, \\text{rel}}, y_{1, \\text{rel}}) = k \\cdot (- y_{0, \\text{rel}}, x_{0, \\text{rel}}),\n",
    "$$\n",
    "where $k=1$ if the rotation is in the positive direction, and $k=-1$ if it is in the negative direction.\n",
    "The new coordinates of the monomer then becomes\n",
    "$$\n",
    "    (x_{\\text{rot}}, y_{\\text{rot}}) = (x_s, y_s) + k \\cdot (-y_{\\text{rel}}, x_{\\text{rel}}) = (x_s, y_s) + k \\cdot (-(y_0 - y_s), x_0 - x_s).\n",
    "$$\n",
    "When implementing this, one can make a small optimization by always rotating the shortest end of the polymer with respect \n",
    "to the rotation center. This reduces the number of computations and ensures that the center of the polymer does not move too \n",
    "much when rotating. This behaviour implies that in the case of a rotation around one of the two end polymers, nothing will get rotated. In the case that the head and tail are equally long, it does not matter which one gets rotated. In our\n",
    "implementation we have defined it to just rotate the tail. In order to speed up the function, we have utilised *NumPy*,\n",
    "slicing and *Numba* JIT-compiling. We will expand on this and the difference between the two versions in the [Benchmarks](#Benchmarks) section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def rotate_polymer(\n",
    "    polymer: np.ndarray, rotation_center: int, positive_direction: bool = True\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Rotates a polymer in the given direction around a monomer\n",
    "\n",
    "    Args:\n",
    "        polymer: A 2D numpy array with monomer coordinates\n",
    "\n",
    "        rotation_center: Which monomer to rotate around\n",
    "        `Note: It is not the index, but the monomer_number. [1, N]`\n",
    "\n",
    "        positive_direction: Rotate in the positive direction if True, or negative direction if False\n",
    "\n",
    "    Returns:\n",
    "        a rotated copy of the polymer\n",
    "    \"\"\"\n",
    "    # Make a slicing array to rotate the correct end of the polymer\n",
    "    rotation_slice = np.full(len(polymer), False)\n",
    "\n",
    "    # Choose to rotate the shortest tail of the polymer\n",
    "    if rotation_center >= len(polymer) / 2:\n",
    "        rotation_slice[rotation_center:] = True\n",
    "    else:\n",
    "        rotation_slice[:rotation_center] = True\n",
    "\n",
    "    if positive_direction:\n",
    "        direction = 1\n",
    "    else:\n",
    "        direction = -1\n",
    "\n",
    "    # The coordinates in space of the rotation center\n",
    "    rotation_position = polymer[rotation_center - 1]\n",
    "\n",
    "    # Where _rel means the position relative to the rotation center\n",
    "    # new_x = x_s + new_x_rel\n",
    "    # new_y = y_s + new_y_rel\n",
    "    # new_x_rel = - (y - y_s) * direction\n",
    "    # new_y_rel = (x - x_s) * direction\n",
    "    new_pos_rel = ((polymer[rotation_slice] - rotation_position) * direction)[:, ::-1]\n",
    "    new_pos_rel[:, 0] *= -1  # Changes the sign of the x-values\n",
    "\n",
    "    # Makes a copy of the polymer\n",
    "    new_polymer = polymer.copy()\n",
    "\n",
    "    new_polymer[rotation_slice] = rotation_position + new_pos_rel\n",
    "    return new_polymer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def rotate_polymer_mut(\n",
    "    polymer: np.ndarray, rotation_center: int, positive_direction: bool = True\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Rotates a polymer in the given direction around a monomer\n",
    "\n",
    "    Args:\n",
    "        polymer: A 2D numpy array with monomer coordinates\n",
    "\n",
    "        rotation_center: Which monomer to rotate around\n",
    "        `Note: It is not the index, but the monomer_number. [1, N]`\n",
    "\n",
    "        positive_direction: Rotate in the positive direction if True, or negative direction if False\n",
    "\n",
    "    Returns:\n",
    "        a rotated copy of the polymer\n",
    "    \"\"\"\n",
    "    # Make a slicing array to rotate the correct end of the polymer\n",
    "    rotation_slice = np.full(len(polymer), False)\n",
    "\n",
    "    # Choose to rotate the shortest tail of the polymer\n",
    "    if rotation_center >= len(polymer) / 2:\n",
    "        rotation_slice[rotation_center:] = True\n",
    "    else:\n",
    "        rotation_slice[:rotation_center] = True\n",
    "\n",
    "    if positive_direction:\n",
    "        direction = 1\n",
    "    else:\n",
    "        direction = -1\n",
    "\n",
    "    # The coordinates in space of the rotation center\n",
    "    rotation_position = polymer[rotation_center - 1]\n",
    "\n",
    "    # Where _rel means the position relative to the rotation center\n",
    "    # new_x = x_s + new_x_rel\n",
    "    # new_y = y_s + new_y_rel\n",
    "    # new_x_rel = - (y - y_s) * direction\n",
    "    # new_y_rel = (x - x_s) * direction\n",
    "    new_pos_rel = ((polymer[rotation_slice] - rotation_position) * direction)[:, ::-1]\n",
    "    new_pos_rel[:, 0] *= -1  # Changes the sign of the x-values\n",
    "\n",
    "    polymer[rotation_slice] = rotation_position + new_pos_rel\n",
    "    return polymer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "Up until now we have defined basic functions to operate on the polymers. Here we will define a bigger function to simulate,\n",
    "multiple rotations, so we can see how the polymers behave when allowed to rotate multiple times. With this we will also be\n",
    "able to benchmark the different variants\n",
    "of the functions above to see which perform the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def simulate_rotations(N: int, Ns: int) -> tuple[np.ndarray, int]:\n",
    "    \"\"\"Simulates rotations of the polymer.\n",
    "    Implementation of algorithm 1 in project description.\n",
    "\n",
    "    Args:\n",
    "        N: length of polymer.\n",
    "        Ns: number of twists (attempts) to be performed.\n",
    "\n",
    "    Returns:\n",
    "        (polymer, number of seccessful twists.)\n",
    "    \"\"\"\n",
    "    counter = 1\n",
    "    pol = generate_flat_polymer(N)\n",
    "    for _ in range(Ns):\n",
    "        # random monomer and random twisting direction\n",
    "        # [2, N) makes sure the end monomers are not chosen as rotation centers\n",
    "        rnd_monomer = np.random.randint(2, N)\n",
    "        rnd_rotate = bool(int(np.random.uniform() + 0.5))\n",
    "\n",
    "        twisted_pol = rotate_polymer(pol, rnd_monomer, rnd_rotate)\n",
    "        valid = check_if_intact(twisted_pol, N)\n",
    "        if valid:\n",
    "            counter += 1\n",
    "            pol = twisted_pol\n",
    "\n",
    "    return pol, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run `simulate_rotations` and visualize the results. First with $N = 15$ and $N_s = 4$, then with $N = 15$ and $N_s = 1000$.\n",
    "<a id=\"simulation_visualization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "polymer_1, _ = simulate_rotations(N = N, Ns = 4)\n",
    "polymer_2, _ = simulate_rotations(N = N, Ns = 1000)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,6))\n",
    "illustrate_polymer(axs[0], polymer_1, cmap=\"Greens\", title=\"$N = 15$, $N_s = 4$\")\n",
    "illustrate_polymer(axs[1], polymer_2, cmap=\"Greens\", title=\"$N = 15$, $N_s = 1000$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks\n",
    "For the simulation algorithms to run fast, the primary functions `rotate_polymer` and `check_if_intact` needs to be implemented in an efficient manner. During our development \n",
    "of these functions we have made several versions with different implementations. Here we benchmark the different versions to see which ones are the fastest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can not be JIT-compiled by Numba because the check_if_intact functions we test\n",
    "# here are not supported by Numba\n",
    "def benchmark_check_if_intact_func(\n",
    "    N: int, Ns: int, check_if_intact_func: Callable[[np.ndarray, int], bool]\n",
    ") -> tuple[np.ndarray, int]:\n",
    "    \"\"\"Simulates rotations to benchmark check_if_intact functions\n",
    "    ---\n",
    "    Args:\n",
    "        N: length of polymer.\n",
    "        Ns: number of twists (attempts) to be performed.\n",
    "        check_if_intact_func: Function to check whether a polymer is intact\n",
    "\n",
    "    Returns:\n",
    "        (polymer, counter)\n",
    "            polymer: polymer.\n",
    "            counter: number of successful twists.\n",
    "    \"\"\"\n",
    "    counter = 1\n",
    "    pol = generate_flat_polymer(N)\n",
    "    for _ in range(Ns):\n",
    "        # random monomer and random twisting direction\n",
    "        rnd_monomer = np.random.randint(2, N)\n",
    "        rnd_rotate = bool(int(np.random.uniform() + 0.5))\n",
    "\n",
    "        twisted_pol = rotate_polymer(pol, rnd_monomer, rnd_rotate)\n",
    "        valid = check_if_intact_func(twisted_pol, N)\n",
    "        if valid:\n",
    "            counter += 1\n",
    "            pol = twisted_pol\n",
    "\n",
    "    return pol, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def benchmark_rotate_mut_func(N: int, Ns: int) -> tuple[np.ndarray, int]:\n",
    "    \"\"\"Simulates rotations to benchmark the rotate_polymer_mut function\n",
    "    ---\n",
    "    Args:\n",
    "        N: length of polymer.\n",
    "        Ns: number of twists (attempts) to be performed.\n",
    "\n",
    "    Returns:\n",
    "        (polymer, counter)\n",
    "            polymer: polymer.\n",
    "            counter: number of successful twists.\n",
    "    \"\"\"\n",
    "    counter = 1\n",
    "    pol = generate_flat_polymer(N)\n",
    "    for _ in range(Ns):\n",
    "        # random monomer and random twisting direction\n",
    "        rnd_monomer = np.random.randint(2, N)\n",
    "        rnd_rotate = bool(int(np.random.uniform() + 0.5))\n",
    "\n",
    "        rotate_polymer_mut(pol, rnd_monomer, rnd_rotate)\n",
    "        if check_if_intact(pol, N):\n",
    "            counter += 1\n",
    "        else:\n",
    "            # Rotates the polymer back if it is invalid\n",
    "            rotate_polymer_mut(pol, rnd_monomer, not rnd_rotate)\n",
    "\n",
    "    return pol, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check_if_intact benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 35\n",
    "Ns = 1000\n",
    "\n",
    "# Check_if_intact is the function used in simulate_rotations\n",
    "print(\"Check_if_intact:\")\n",
    "%timeit simulate_rotations(N, Ns)\n",
    "\n",
    "print()\n",
    "print(\"Check_if_intact_1:\")\n",
    "%timeit benchmark_check_if_intact_func(N, Ns, check_if_intact_1)\n",
    "\n",
    "print()\n",
    "print(\"Check_if_intact_2:\")\n",
    "%timeit benchmark_check_if_intact_func(N, Ns, check_if_intact_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the `check_if_intact` function is indeed the fastest one. The reason is largely due to *Numba* and the \n",
    "JIT-compiler. When using the `@njit` \n",
    "decorator, we let *Numba* compile the\n",
    "function to native machine code which gives a massive performance benefit over regular python code. [See the documentation]\n",
    "(https://numba.readthedocs.io/en/stable/user/overview.html).\n",
    "The other two results are expected, but still interesting. Although `check_if_intact_1`\n",
    "technically has the theoretical best time complexity due to the early return implementation, it still gets beaten by \n",
    "`check_if_intact_2`. The reason being that \n",
    "`check_if_intact_2` utilizes *Numpy*\n",
    "functionality, which to a large extent is written in C. The early return optimization is nice, but it is not enough to beat the heavily optimized *Numpy* operations. The \n",
    "penalty of going through the\n",
    "entire matrix is simply not big enough to matter with polymer sizes capped at 35. Another point to mention is why we do not use *Numba* for the `check_if_intact_i` \n",
    "functions. This is because the full\n",
    "version of the np.unique() function is not supported by *Numba*, which both functions use.\n",
    "\n",
    "From the above there indication towards that the JIT-compiled version runs the fastest for our problem. This is however not necessarily the case for bigger polymers. To \n",
    "see how well the algorithms\n",
    "scale with $N$, we have to divide the functions into to parts. One for the part that checks for overlap of the polymer, call it part one, and one part to check whether all consecutive monomers are \n",
    "closest neighbours, call it\n",
    "part two.\n",
    "\n",
    "Let us start with,\n",
    "`check_if_intact`. In part one we effectively loop over two copies of the polymer in a double loop. The time complexity for this part then scales with $N^2$.,\n",
    "In part two we sum $N-1$ elements with $N-1$ other elements twice, take the absolute value, and sum the two results. Lastly we check for elements different from one. All \n",
    "these chained operations are\n",
    "linear with respect to $N$, and the total is therefore linear. The entire function then scales as $N^2$ because of part one.\n",
    "\n",
    "Now we look at `check_if_intact_1`. Part one uses np.unique which has a time complexity of $O(N\\log N)$ as it uses lexiographical sorting to check for uniqeness.\n",
    "[See the documentation](https://github.com/numpy/numpy). The size lookup is done in constant\n",
    "time, so the entire part\n",
    "scales as $n\\log n$. Part two does the same operations as in `check_if_intact`, just implemented in `Python`, and scales as $N$. The early return optimization \n",
    "effectively multiplies the average time\n",
    "with a constant, so the total still scales as $N$. The entire function then scales as $N\\log N$ which is actually faster\n",
    "than `check_if_intact`.\n",
    "\n",
    "Lastly we look at `check_if_intact_2`. Part one is identical to `check_if_intact_1` and part two is identical to `check_if_intact`, and so the entire function scales as \n",
    "$N\\log N$.\n",
    "\n",
    "From this we actually see that `check_if_intact` scales the worst with $N$. This can however be fixed with a change in part one. If we were to implement a sorting \n",
    "algorithm as in np.unique we would\n",
    "have reduced the time complexity to $N\\log N$ which is the same as the others. One might also be able to hash the rows of the matrix into a hash-set, which has constant \n",
    "lookup and addition of new\n",
    "element. When searching for overlap, the inner loop could then be replaced by a simple lookup, resulting in a linear complexity. The entire function would then scale \n",
    "linearly with $N$.,\n",
    "When operating with polymer sizes big enough for these optimizations, there is one more thing to do. It is to completely remove the check of whether the polymer has been \n",
    "broken. They way the\n",
    "rotate_polymer is implemented, it preserves the connections between consecutive monomers, and will not break the polymer. What needs to checked is just whether an overlap \n",
    "has happened."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotate_polymer_mut benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 35\n",
    "Ns = 1000\n",
    "\n",
    "print(\"simulate_rotations\")\n",
    "%timeit simulate_rotations(N, Ns)\n",
    "\n",
    "print()\n",
    "print(\"Rotate_polymer_mut:\")\n",
    "%timeit benchmark_rotate_mut_func(N, Ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we see that both implementations are about equally fast. Although one may be slightly faster, both lie within \n",
    "each others standard deviation, and we cannot conclude which one is the fastest. If we look at the time complexity of the \n",
    "two, this should also be the expected result. Most of the functions are identical, with the exception of a copy statement in \n",
    "one.\n",
    "\n",
    "If we begin with the mutating function, we see that the first statement is an allocation which runs in $O(N)$. In the \n",
    "next if-statement, we fill the shortest end of the polymer with values. Let us denote the number of elements in the part of \n",
    "the polymer we are trying to rotate, as $n$. We know that $1 \\le n \\le \\lfloor \\frac{N}{2} \\rfloor$ for all $n$, and is \n",
    "therefore bounded by a linear function in $N$. *Note that in both `metropolis` and `simulate_rotations` we exclude the end \n",
    "monomers from becoming the rotation center, resulting in $n$ being strictly bigger than 0*. Since $n$ always can take a value equal to $\\lfloor \\frac{N-1}{2} \\rfloor$, it \n",
    "is clear that a function\n",
    "that scales as $O(n)$, also scales as $O(N)$ on average. In \n",
    "the rest of the function we only add vectors together or multiply them by scalars. All of these operations run in $O(n)$ and \n",
    "therefore \n",
    "$O(N)$. Because of this the entire function runs as $O(N)$. When using this variant to rotate polymers you run the risk of \n",
    "having to run the function twice if the rotation is invalid. This just multiplies the complexity by a factor of two, and the \n",
    "total still runs as $O(N)$.\n",
    "\n",
    "When looking at the non-mutating function we just add a copy-statement, which runs as $O(N)$. The entire function therefore \n",
    "runs as $O(N)$ as well. This means that any difference between the two functions comes down to the unknown coefficients we \n",
    "left out when we invoked the Big-$O$ notation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid rotations\n",
    "\n",
    "As [already](#Validation) discussed not all rotations are considered valid. A rotation is not valid if it causes some monomers to have the same coordinates, i.e. overlap.\n",
    "Let's investigate the percentage of valid rotations as a function of $N$ for various values for $N_s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "N_lower = 5\n",
    "N_upper = 100\n",
    "N = np.arange(N_lower, N_upper)\n",
    "N_s = (10, 50, 500, 1_000, 50_000)\n",
    "\n",
    "# preparing array\n",
    "percentages = np.zeros((len(N_s), len(N)))\n",
    "\n",
    "# run the simulation\n",
    "for i, _N_s in enumerate(N_s):\n",
    "    for j, _N in enumerate(N):\n",
    "        _, valid_states = simulate_rotations(N=_N, Ns=_N_s)\n",
    "        percentages[i, j] = (valid_states - 1)/_N_s   # subtract 1 because the initial state is always valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results for the cell above\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, _percentages in enumerate(percentages):\n",
    "    ax.plot(N, _percentages, label=f\"$N_s = {N_s[i]}$\")\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"$N$\",\n",
    "    ylabel=\"\",\n",
    "    xlim=(5,N[-1]),\n",
    "    ylim=(0, 1),\n",
    "    xticks=np.arange(N_lower,N_upper,10),\n",
    "    yticks=np.arange(0,1.1,0.10),\n",
    "    title=\"Percentage of valid rotations a polymer is exposed to\"\n",
    ")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph we see that a higher $N_s$ gives lower volatility. For $N_s = 10$ and $N_s = 50$ the randomness is prominent. Larger values for $N_s$ gives more rotations and thus each rotation matter less for the total percentage. This gives rise to the smoothing of the graph.\n",
    "It is noteworthy that the percentage of valid rotations decreases as $N$ increases, but seems to converge to some value around $43 \\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy\n",
    "The energy of the polymer is defined as follows:\n",
    "\n",
    "$$\n",
    "    E = \\frac{1}{2} \\sum_{m, n} V_{mn} b_{mn}\n",
    "$$\n",
    "\n",
    "The $N\\times N$-matrix $V$ is a constant while the quantity $b_{mn}$ has to be calculated for each step:\n",
    "\n",
    "\\begin{equation}\n",
    " b_{mn} =\n",
    "  \\begin{cases}\n",
    "  1 & m \\text{ and } n \\text{ closest neighbours} \\\\\n",
    "  0 & \\text{otherwise} \n",
    "  \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to generate the $V$-matrix proves to be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_V_matrix(\n",
    "    size: int, fill_value: float | tuple[float, float] = -1.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    With fill_value = -1.0 gen_V_matrix generates a size*size matrix:\n",
    "         0  0 -1 -1 ... -1 -1 -1\n",
    "         0  0  0 -1 ... -1 -1 -1\n",
    "        -1  0  0  0 ... -1 -1 -1\n",
    "        .          .           .\n",
    "        .            .         .\n",
    "        .              .       .\n",
    "        -1 -1 -1 -1 ...  0  0  0\n",
    "        -1 -1 -1 -1 ... -1  0  0\n",
    "\n",
    "    Args:\n",
    "        size: size of array\n",
    "        fill_value: float | tuple[lower, upper]\n",
    "            if fill_value is a 2-tuple then \n",
    "            the fill_values are drawn from\n",
    "            a uniform distribution on [lower, upper].\n",
    "\n",
    "    Returns:\n",
    "        the matrix\n",
    "    \"\"\"\n",
    "    if type(fill_value) == float:\n",
    "        V = np.full((size, size), fill_value)\n",
    "\n",
    "    else:\n",
    "        assert len(fill_value) == 2, \"There is an error in the type of fill_value\"\n",
    "        rng = np.random.default_rng()\n",
    "        V = np.zeros((size, size))\n",
    "        for i in range(1, size):\n",
    "            for j in range(i):\n",
    "                value = rng.uniform(fill_value[0], fill_value[1])\n",
    "                V[i, j] = value\n",
    "                V[j, i] = value\n",
    "\n",
    "    # filling the diagonals with zeros can be done in the for-loops,\n",
    "    # but this is easier to read and is more foolproof\n",
    "    np.fill_diagonal(V, 0)\n",
    "    np.fill_diagonal(V[:-1, 1:], 0)\n",
    "    np.fill_diagonal(V[1:, :-1], 0)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calculate_energy` also has to be optimized for speed in the same manner as `check_if_intact` and `rotate_polymer`.\n",
    "\n",
    "The most time consuming part of calculate_energy is to fill the $b$-matrix based on which monomers are neighbours. \n",
    "We wrote two implementations that both have their strengths and weaknesses. The first one, `calculate_energy_1`, exploits the \n",
    "symmetry of the problem and only fills the lower half of the $b$-matrix, as it is a symmetric matrix otherwise. This roots in the fact that if monomers $m$ and $n$ are closest neighbours, then monomers $n$ and $m$ are also closest neighbours.\n",
    "This way it never checks the same two monomers twice. A slight optimalization is to also never check the the next monomer in \n",
    "the chain, as they will never interact with each other, making the check redundant.\n",
    "This results \n",
    "in fewer memory writes and no double counting. The downside of this method is that it uses python `for`-loops. The other \n",
    "method, `calculate_energy`, uses *NumPy* operations exclusively for speed of computation, but has the downside that it uses \n",
    "more memory and checks the same pair of monomers twice. However, for the polymer sizes we operate with, the extra memory \n",
    "usage should be negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def calculate_energy_1(polymer: np.ndarray, V: np.ndarray) -> float:\n",
    "    \"\"\"Calculates the energy of the given polymer.\n",
    "\n",
    "    Args:\n",
    "        polymer: A 2D numpy array with monomer coordinates\n",
    "\n",
    "        V: A matrix with the strength of the interaction between monomers of the given polymer.\n",
    "        V[i, j] = V[j, i] = strength between monomer number (i+1) og (j+1)\n",
    "\n",
    "    Returns:\n",
    "        The energy of the polymer\n",
    "    \"\"\"\n",
    "    N = len(polymer)\n",
    "    # A matrix which tells if monomer (i+1) and (j+1) are neighbours. b_matrix[i, j] = 1 if they are, and 0 otherwise\n",
    "    b_matrix = np.zeros((N, N))\n",
    "    for i in range(0, N):\n",
    "        # We only need to look at monomer combinations which we have not checked yet.\n",
    "        # The next monomer in the polymer does not interact with the given monomer, so we don't have to check it.\n",
    "        for j in range(i + 2, N):\n",
    "            # Only \"closest neighbour\"-coordinates will give a euclidian distance of exactly one, so we dont have to take the square root.\n",
    "            if np.sum((polymer[i] - polymer[j]) ** 2) == 1:\n",
    "                # We only need to fill the lower triangle of the matrix, as it otherwise will just be symmetric.\n",
    "                # Note: j>i\n",
    "                b_matrix[j, i] = 1\n",
    "    # Don't have to divide by two, because we only filled the lower triangle of the b_matrix.\n",
    "    # We don't count the same interaction twice\n",
    "    return float(np.sum(V * b_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calculate_energy(polymer: np.ndarray, V: np.ndarray) -> float:\n",
    "    \"\"\"Calculates the energy of the given polymer.\n",
    "    \n",
    "     Args:\n",
    "        polymer: A 2D numpy array with monomer coordinates\n",
    "\n",
    "        V: A matrix with the bonding energies for the monomers of the given polymer.\n",
    "        V[i, j] = V[j, i] = bonidng energy for the bond between monomer number (i+1) and (j+1).\n",
    "\n",
    "    Returns:\n",
    "        The energy of the polymer\"\"\"\n",
    "    N = len(polymer)\n",
    "    L = np.repeat(polymer, N).reshape(2 * N, N)\n",
    "    b = np.where(\n",
    "        ((L[::2] - L[::2].transpose()) ** 2 + (L[1::2] - L[1::2].transpose()) ** 2)\n",
    "        == 1,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    return 0.5 * (np.sum(V * b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An explanation of the inner workings of `calculate_energy` is found at the end.<a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate_energy benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 35\n",
    "Ns = 1000\n",
    "V = gen_V_matrix(N)\n",
    "polymer, _ = simulate_rotations(N, Ns)\n",
    "\n",
    "print(\"\\ncalculate_energy\")\n",
    "%timeit calculate_energy(polymer, V)\n",
    "\n",
    "print(\"\\ncalculate_energy_1\")\n",
    "%timeit calculate_energy_1(polymer, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for the first run (remember to restart the kernel) both `calculate_energy` and `calculate_energy_1` has high \n",
    "standard deviations.\n",
    "For `calculate_energy` timeit even gives this warning: \"This could mean that an intermedaite result is being cached\".\n",
    "Running the cell a second time however, shows that `calculate_energy` is faster than `calculate_energy_1`.\n",
    "This is due to *Numba*'s Just In Time compilation. When the function is called the first time *Numba* compiles to machine code \n",
    "such that the subsequent calls are faster.\n",
    "\n",
    "What is interesting is that `calculate_energy` is faster than `calculate_energy_1`, even though `calculate_energy_1` does \n",
    "less than half the number of operations of `calculate_energy`. This only goes to show how slow python really is compared to \n",
    "lower level languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `calculate_energy`\n",
    "\n",
    "Let us fill the $V$-matrix with $-1$ and calculate the energy for the two polymers generated [earlier](#Simulation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "V = gen_V_matrix(size = N, fill_value = -1.0)\n",
    "E_1 = calculate_energy(polymer_1, V)\n",
    "E_2 = calculate_energy(polymer_2, V)\n",
    "\n",
    "print(f\"Energy_1: {E_1}\\nEnergy_2: {E_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the [visualizations](#simulation_visualization) for the two polymers we see that ... and therefore the resulting energies $E_1 = $ and $E_2 = $ is as expected. \n",
    "\n",
    "# **TODO:** f√∏r innlevering kj√∏r en siste gang og fyll inn!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now that the basic functionality has been implemented and tested for speed it is time to run some larger simulations!\n",
    "\n",
    "## Larger simulations and investigations of physical quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`metropolis` is our implementation of the metropolis algorithm for the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def metropolis(\n",
    "    pol: np.ndarray, N_s: int, V: np.ndarray, T: float\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Runs the Metropolis-algorithm\n",
    "\n",
    "    Args:\n",
    "        pol: Polymer initial state\n",
    "        N_s: Rotation attempts\n",
    "        V: Interaction forces between two monomers\n",
    "        T: Temperature (Kelvin)\n",
    "\n",
    "    Returns:\n",
    "        (Last polymer created, array with all simulated energies)\n",
    "    \"\"\"\n",
    "    E_array = np.zeros(N_s)\n",
    "    N = len(pol)\n",
    "    E = calculate_energy(pol, V)\n",
    "    i = 0\n",
    "    while i < N_s - 1:\n",
    "        # random monomer and random twisting direction\n",
    "        # [2, N) makes sure the end monomers are not chosen as rotation centers\n",
    "        rnd_monomer = np.random.randint(2, N)\n",
    "        rnd_rotate = bool(int(np.random.uniform() + 0.5))\n",
    "\n",
    "        twisted_pol = rotate_polymer(pol, rnd_monomer, rnd_rotate)\n",
    "        if check_if_intact(twisted_pol, N):\n",
    "            i += 1\n",
    "            E_new = calculate_energy(twisted_pol, V)\n",
    "\n",
    "            if E_new < E:\n",
    "                pol = twisted_pol\n",
    "                E = E_new\n",
    "\n",
    "            elif np.random.uniform() < np.exp(-(E_new - E) / (T * Boltzmann)):\n",
    "                pol = twisted_pol\n",
    "                E = E_new\n",
    "            E_array[i] = E\n",
    "\n",
    "    return pol, E_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"metropolis_first_simulation\"></a>\n",
    "#### First simulation and temperature dependance\n",
    "\n",
    "Let us run two simulations of `metropolis`.\n",
    "\n",
    "We fixate $N = 30$, $N_s = 5000$ and\n",
    "\n",
    "$$V =\n",
    "  \\begin{bmatrix}\n",
    "   0& 0 & & &  &  & & &\\\\\n",
    "   0& 0 & 0 & &  &  ‚àí4.0&  \\cdot& 10^{‚àí21} &\\text{J}\\\\\n",
    "   & 0 & 0 & 0 &  &  &  &  & \\\\\n",
    "   &  & 0 & 0 &  &  &  &  & \\\\\n",
    "   &  &  &  &  \\ddots&  & &  & \\\\\n",
    "   &  &  &  &  &  0&  0&  & \\\\\n",
    "   &  &  &  &  &  0&  0&  0& \\\\\n",
    "   ‚àí4.0&  \\cdot& 10^{‚àí21} &\\text{J}  &  &  &  0&  0& 0\\\\\n",
    "   &  &  &  &  &  &  &  0& 0\\\\\n",
    "  \\end{bmatrix}$$\n",
    "\n",
    "In order to look at how the temperature affects the polymer we use the following values:\n",
    "\n",
    "\\begin{align}\n",
    "T_\\text{low} &= 70 \\,\\text{K} \\\\\n",
    "T_\\text{high} &= 350 \\,\\text{K}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "N = 30\n",
    "Ns = 5000\n",
    "V = gen_V_matrix(size=N, fill_value=-4e-21)\n",
    "T_low = 70\n",
    "T_high = 350\n",
    "\n",
    "# run the simulation\n",
    "polymer_low, E_low = metropolis(generate_flat_polymer(N), N_s=Ns, V=V, T=T_low)\n",
    "polymer_high, E_high = metropolis(generate_flat_polymer(N), N_s=Ns, V=V, T=T_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the energy $E$ as function of iteration step $t$ for the two temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(E_low, label=f\"$E(t)$ at ${T_low}$ K\")\n",
    "ax.plot(E_high, label=f\"$E(t)$ at ${T_high}$ K\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set(\n",
    "    title=\"Simulation using the Metropolis algorithm at different temperatures\",\n",
    "    xlabel=\"$t$\",\n",
    "    ylabel=\"$E\\,[J]$\",\n",
    "    xlim=(0,Ns)\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the plot that increasing the temperature results in the polymer occupying more energy states.\n",
    "Therefore it has a higher probability of exploring the states that has the lowest energy.\n",
    "Due to the high temperature the polymer is more \"wiggly\" and thus has a lower probability of getting stuck in a local minima.\n",
    "The polymer at the lower temperature struggles to get out of such wells and thus the graph of the energy function is flatter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "illustrate_polymer(axs[0], polymer_low, cmap=\"Greens\", title=f\"$T = {T_low} $K\")\n",
    "illustrate_polymer(axs[1], polymer_high, cmap=\"Greens\", title=f\"$T = {T_high} $K\")\n",
    "fig.suptitle(f\"The final state of the polymer after attempting {Ns} rotations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to extract useful information from looking at a single iteration of a stochastic simulation.\n",
    "The rotations (and thus the energy levels) are subject to randomness.\n",
    "However, analyzing the distribution of the energies ($E(t)$) provides insights about the system.\n",
    "\n",
    "Looking at the final positions of the polymers above we see that...\n",
    "\n",
    "Even though this was the result at the time of writing, the next run will produce a different result.\n",
    "\n",
    "# **TODO: etter siste kj√∏ring f√∏r innlevering: fyll inn resultater og diskusjon**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the $V$-matrix\n",
    "\n",
    "The $V$-matrix holds information about how different monomers interact with each other.\n",
    "Using different matrices (ensuring that they remain symmetric) one can model proteins with different structures.\n",
    "Let us experiment a bit with the setup of $V$:\n",
    "\n",
    "- **Setup 1**\\\n",
    "  Instead of using negative entries in $V$ as in the [previous](#metropolis_first_simulation) simulation we now choose the entries to be positive.\n",
    "  The physical interpretation of this is that the monomers now repel each other and we therefore expect the polymer to stay pretty flat.\n",
    "\n",
    "- **Setup 2**\\\n",
    "  Scaling all entries by a factor of $100$ and setting the signs of entries at the upper right and lower left corners to be negative and all other entries to be positive.\n",
    "  By doing this we expect the polymer to form a ring since the middle monomers are repelling and the ends are attracting.\n",
    "  The chance of getting a ring increases if we give the polymer enough time (setting $N_s$ to be large enough) and make the ends \"sticky\" (by scaling the entries of $V$).\n",
    "\n",
    "- **Setup 3**\\\n",
    "  In the last setup we scale a single entry in $V_{1k}$ by a factor of $100$ (making sure the matrix is symmetric by also scaling $V_{k1}$).\n",
    "  Interpreting the entry $V_{mn}$ as the \"bonding strength\" between monomers $m$ and $n$ we would expect that once the monomers $1$ and $k$ comes in contact they will remain in contact for the rest of the simulation. Let's fixate $k$ to be $\\lfloor N / 2 \\rfloor$.\n",
    "    \n",
    "In order to look at these cases we will run `metropolis` on a polymer of length 30 at temperature $T = 150$ K and visualize the resulting polymers and energy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "N = 30\n",
    "Ns = 5000\n",
    "scaling = 100\n",
    "T = 150\n",
    "fill_value = -4e-21\n",
    "\n",
    "# Creating the matrices\n",
    "# setup 1\n",
    "V1 = gen_V_matrix(size=N, fill_value=-fill_value)\n",
    "\n",
    "# setup 2\n",
    "V2 = gen_V_matrix(size=N, fill_value=fill_value*scaling)\n",
    "for i in range(2, N-2):\n",
    "    np.fill_diagonal(V2[:-i, i:], -fill_value*scaling)\n",
    "    np.fill_diagonal(V2[i:, :-i], -fill_value*scaling)\n",
    "\n",
    "# setup 3\n",
    "V3 = gen_V_matrix(size=N, fill_value=fill_value)\n",
    "V3[0, int(N/2)] *= scaling\n",
    "V3[int(N/2), 0] *= scaling\n",
    "\n",
    "# running the simulation\n",
    "pol1, E_array1 = metropolis(pol=generate_flat_polymer(N), N_s=Ns, V=V1, T=T)\n",
    "pol2, E_array2 = metropolis(pol=generate_flat_polymer(N), N_s=Ns, V=V2, T=T)\n",
    "pol3, E_array3 = metropolis(pol=generate_flat_polymer(N), N_s=Ns, V=V3, T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and visualization for the cell above\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axs[1, 0].plot(\n",
    "    E_array1\n",
    ")\n",
    "axs[1, 1].plot(\n",
    "    E_array2\n",
    ")\n",
    "axs[1, 2].plot(\n",
    "    E_array3\n",
    ")\n",
    "axs[1, 0].set(\n",
    "    title=\"Setup 1 - Energy as function of iteration step\",\n",
    "    xlabel=\"$t$\",\n",
    "    ylabel=\"$E\\,[J]$\",\n",
    "    xlim=(0,Ns)\n",
    ")\n",
    "axs[1, 1].set(\n",
    "    title=\"Setup 2  - Energy as function of iteration step\",\n",
    "    xlabel=\"$t$\",\n",
    "    ylabel=\"$E\\,[J]$\",\n",
    "    xlim=(0,Ns)\n",
    ")\n",
    "axs[1, 2].set(\n",
    "    title=\"Setup 3 - Energy as function of iteration step\",\n",
    "    xlabel=\"$t$\",\n",
    "    ylabel=\"$E\\,[J]$\",\n",
    "    xlim=(0,Ns)\n",
    ")\n",
    "\n",
    "illustrate_polymer(axs[0, 0], pol1, cmap=\"Greens\", title=\"Setup 1 - Final state for the polymer\")\n",
    "illustrate_polymer(axs[0, 1], pol2, cmap=\"Greens\", title=\"Setup 2 - Final state for the polymer\")\n",
    "illustrate_polymer(axs[0, 2], pol3, cmap=\"Greens\", title=\"Setup 3 - Final state for the polymer\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at setup $1$'s energy plot we see that $E$ mostly remain at the lower energy steps ($0$ J and $4.0 \\cdot 10^{-21}$ J). For the chosen temperature we see some fluctiations, but the polymer generally keeps its flat profile.\n",
    "\n",
    "On the contrary, in setup 2 the polymer har formed a ring. The energy function also clearly shows that once the ends bond, they stay bonded.\n",
    "The exact form of the ring is subject to the random rotations that took place before the bonding.\n",
    "\n",
    "Energy considerations of setup 3 resembles that of setup 2, but has fluctiations after the bonding has occured.\n",
    "Predicting the form of the polymer is more difficult, but we would at least expect monomers $1$ and $k$ to be closest neighbours. This is clearly the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy and it's dependance on temperatue\n",
    "\n",
    "By running `metropolis` over a range of temperatures we can calculate $<E>(T)$ and $\\sigma_E(T)$.\n",
    "Because all polymers starts out as flat polymers we exclude the first $1000$ steps of each simulation.\n",
    "This is such that the polymers' starting position do not affect $<E>(T)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "T_interval = np.arange(10, 1000, 30)\n",
    "N = 30\n",
    "Ns = (1050, 5000, 50_000)\n",
    "V = gen_V_matrix(N, fill_value=-4e-21)\n",
    "\n",
    "# Preparing arrays\n",
    "E_mean = np.zeros((len(Ns), len(T_interval)))\n",
    "E_std = np.zeros((len(Ns), len(T_interval)))\n",
    "\n",
    "# running metropolis for all Ts in T_interval and calculating the mean and standard deviation.\n",
    "for i, _Ns in enumerate(Ns):\n",
    "    for j, T in enumerate(T_interval):\n",
    "        pol = generate_flat_polymer(N)\n",
    "        pol, E_array = metropolis(pol=pol, N_s=_Ns, V=V, T=T)\n",
    "        E_mean[i, j] = np.mean(E_array[1000:])\n",
    "        E_std[i, j] = np.std(E_array[1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(Ns), figsize=(6*len(Ns), 6))\n",
    "\n",
    "for i, _Ns in enumerate(Ns): \n",
    "    axs[i].errorbar(\n",
    "        T_interval,\n",
    "        E_mean[i],\n",
    "        yerr=E_std[i],\n",
    "        fmt=\".\",\n",
    "        capsize=3,\n",
    "        label=f\"$N_s = {_Ns}$\"\n",
    "    )\n",
    "    axs[i].set(\n",
    "        xlabel=\"$T\\,[K]$\",\n",
    "        ylabel=\"$<E>\\, [J]$\",\n",
    "        xlim=(0, 1000)\n",
    "    )\n",
    "    axs[i].legend()\n",
    "\n",
    "fig.suptitle(\"Energy as function of temperature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing $N_s$ seems give rise to a smoothing effect of the energy expectation value and its deviation.\n",
    "One can explain this by interpereting $<E>$ as an estimator for the expectation value of the energy.\n",
    "Since $\\frac{1}{N_s} \\sum_t E(t)$ converges to $\\text{E}[E]$ as $t \\to \\infty$, increasing $N_s$ would then give more accurate results.\n",
    "\n",
    "However, at lower temperatures the standard deviation is lower and suggests that the polymer gets \"stuck\" in a local minima.\n",
    "From the above plots the energy seems to be lowest at around $150$ K, but running the simulation multiple times give different results for lower temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy at lower temperatures\n",
    "\n",
    "Let us take a closer look at $T = 70$ K by running $10$ simulations at this temperature and plot $E(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "T = 70\n",
    "num_simulations = 10\n",
    "N = 30\n",
    "Ns = 50000\n",
    "V = gen_V_matrix(N, fill_value=-4e-21)\n",
    "\n",
    "# Preparing array\n",
    "E_array_array = np.zeros((num_simulations, Ns))\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    pol = generate_flat_polymer(N)\n",
    "    pol, E_array = metropolis(pol=pol, N_s=Ns, V=V, T=T)\n",
    "    E_array_array[i] = E_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the results from the cell above\n",
    "fig, ax = plt.subplots()\n",
    "for E_arr in E_array_array:\n",
    "    ax.plot(E_arr)\n",
    "\n",
    "ax.set(\n",
    "    title=\"$E$ as function of iteration step in $10$ simulations at $T = 70$ K\",\n",
    "    xlabel=\"$t$\",\n",
    "    ylabel=\"$E\\,[J]$\",\n",
    "    xlim=(0, Ns)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can see that polymers at low temperatures tend to be quite stable once they have reached a reasonably \n",
    "low energy state. With the exception of the initial steps, the polymers energies plateaus at a lower energy state than the \n",
    "initial energy, where they tend to stay for the rest of the simulation. We also observe that the different polymers do not \n",
    "stabilize at the same energy level, but rather at comparatively big energy differences between each other. This indicates \n",
    "that after the initial steps, the polymers gets locked into a local energy minima where they may randomly fluctuate to a \n",
    "small extent above the minima, but rarely enough escape it. If they do escape it, they tend to drop to an even\n",
    "lower energy level where they stabilize themselves again.\n",
    "\n",
    "The fact that they stabilize at different energy levels is important to note, as it makes determining the average energy of a \n",
    "polymer at low temperatures with only one simulation insufficient. Because the polymer falls into different local minimas\n",
    "during the initial steps, we need to simulate several polymers to explore the different minimas. From this we can make an \n",
    "estimate of the average energy by taking the empirical average over all the simulations. With this method we will be\n",
    "able to get a more accurate result as opposed to just running one simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about the polymers spacial extent?\n",
    "\n",
    "The diameter of a polymer is defined as the largest euclidean distance between two unique monomers.\n",
    "\n",
    "`calculate_diameter` calculates all the distances between the monomers before returning the largest distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit  \n",
    "def calculate_diameter(polymer: np.ndarray) -> float:\n",
    "    \"\"\"Finds the diameter of a polymer\n",
    "\n",
    "    Args:\n",
    "        polymer (np.ndarray): the polymer to find the diameter of\n",
    "\n",
    "    Returns:\n",
    "        float: diameter of the polymer\n",
    "    \"\"\"\n",
    "    N = len(polymer)\n",
    "    L = np.repeat(polymer, N).reshape(2 * N, N)\n",
    "    return np.sqrt(\n",
    "        np.max(\n",
    "            (L[::2] - L[::2].transpose()) ** 2 + (L[1::2] - L[1::2].transpose()) ** 2\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the implementation of the metropolis algorithm with the diameter calculation integrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def metropolis_diameter(\n",
    "    pol: np.ndarray, N_s: int, V: np.ndarray, T: float\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Metropolis algorithm with diameter calculation\n",
    "\n",
    "    Args:\n",
    "        pol: polymer start shape\n",
    "        N_s: Number of attempts at rotation\n",
    "        V: Interaction between monomers\n",
    "        T: temperature in kelvin\n",
    "\n",
    "    Returns:\n",
    "        (output array, array with all energies, array with all diameters)\n",
    "    \"\"\"\n",
    "    E_array = np.zeros(N_s)\n",
    "    Dia_array = np.zeros(N_s)\n",
    "    N = len(pol)\n",
    "    E = calculate_energy(pol, V)\n",
    "    i = 0\n",
    "    while i < N_s - 1:\n",
    "        # random monomer and random twisting direction\n",
    "        rnd_monomer = np.random.randint(2, N)\n",
    "        rnd_rotate = bool(int(np.random.uniform() + 0.5))\n",
    "\n",
    "        twisted_pol = rotate_polymer(pol, rnd_monomer, rnd_rotate)\n",
    "        if check_if_intact(twisted_pol, N):\n",
    "            i += 1\n",
    "            E_new = calculate_energy(twisted_pol, V)\n",
    "\n",
    "            if E_new < E:\n",
    "                pol = twisted_pol\n",
    "                E = E_new\n",
    "            \n",
    "            elif np.random.uniform() < np.exp(-(E_new - E) / (T * Boltzmann)):\n",
    "                pol = twisted_pol\n",
    "                E = E_new\n",
    "            E_array[i] = E\n",
    "            Dia_array[i] = calculate_diameter(pol)\n",
    "\n",
    "    return pol, E_array, Dia_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating rotation and diameter for different temperatures, with a flat polymer generated as the starting point for each temperature.\n",
    "\n",
    "The last simulation goes through the temperature array from high to low, and uses the resulting polymer from the previous temperature as the starting polymer for the next temperature.   \n",
    "This process best describes cooling down a polymer.\n",
    "\n",
    "As with the energy simulations we exclude the first 1000 rotations.\n",
    "\n",
    "We chose Ns as XXXXX, which is sufficiently large to give stable results for average and sandard deviation, but does not cause the simulations to take too much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "T_interval = np.arange(10, 1000, 30)\n",
    "N = 30\n",
    "Ns = 50_000\n",
    "V = gen_V_matrix(N, fill_value=(-6*10**(-21), -2*10**(-21))) \n",
    "\n",
    "\n",
    "E_mean = np.zeros(len(T_interval))\n",
    "E_std = np.zeros(len(T_interval))\n",
    "\n",
    "d_mean = np.zeros(len(T_interval))\n",
    "d_std = np.zeros(len(T_interval))\n",
    "\n",
    "E_rep_mean = np.zeros(len(T_interval))\n",
    "E_rep_std = np.zeros(len(T_interval))\n",
    "\n",
    "d_rep_mean = np.zeros(len(T_interval))\n",
    "d_rep_std = np.zeros(len(T_interval))\n",
    "\n",
    "T_rep_interval = np.flip(T_interval)\n",
    "\n",
    "start_2g = time.perf_counter()\n",
    "for i, T in enumerate(T_interval): # Runs metropolis for t_interval\n",
    "        pol = generate_flat_polymer(N)\n",
    "        pol, E_array, d_array = metropolis_diameter(pol=pol, N_s=Ns, V=V, T=T)\n",
    "\n",
    "        d_mean[i] = np.mean(d_array[1000:])\n",
    "        d_std[i] = np.std(d_array[1000:])\n",
    "\n",
    "        E_mean[i] = np.mean(E_array[1000:])\n",
    "        E_std[i] = np.std(E_array[1000:])\n",
    "        \n",
    "end_2g = time.perf_counter() - start_2g\n",
    "print(f\"Time for all simulations(task 2g): {end_2g:.2f} seconds\")\n",
    "\n",
    "pol_rep = generate_flat_polymer(N) # Starting polymer for the reversed temperature\n",
    "for i, T in enumerate(T_rep_interval): # runs metropolis for the reversed temperatures\n",
    "        pol_rep, E_array, d_array = metropolis_diameter(pol=pol_rep, N_s=Ns, V=V, T=T)\n",
    "\n",
    "        d_rep_mean[-i-1] = np.mean(d_array[1000:])\n",
    "        d_rep_std[-i-1] = np.std(d_array[1000:])\n",
    "\n",
    "        E_rep_mean[-i-1] = np.mean(E_array[1000:])\n",
    "        E_rep_std[-i-1] = np.std(E_array[1000:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the diameter for different temperatures.\n",
    "fig, (ax1, ax2) = plt.subplots(nrows= 1, ncols=2, figsize = (18, 6))\n",
    "\n",
    "ax1.errorbar(\n",
    "    T_interval,\n",
    "    d_mean,\n",
    "    yerr=d_std,\n",
    "    fmt=\".\",\n",
    "    capsize=3,\n",
    "    label=r\"$<d>(T)$\"\n",
    ")\n",
    "\n",
    "ax1.set(\n",
    "    title=\"Diameter different temperatures\",\n",
    "    xlabel=\"$T$ [K]\",\n",
    "    ylabel=\"$<d>(T)$ [unit length]\",\n",
    "    xticks=T_interval[::2],\n",
    "    xlim=(0,1000)\n",
    ")\n",
    "\n",
    "ax2.errorbar(\n",
    "    T_interval,\n",
    "    E_mean,\n",
    "    yerr=E_std,\n",
    "    fmt=\".\",\n",
    "    capsize=3,\n",
    "    label=r\"$<E>(T)$\",\n",
    "    color = \"r\"\n",
    ")\n",
    "\n",
    "ax2.set(\n",
    "    title=\"Energy different temperatures\",\n",
    "    xlabel=\"$T$ [K]\",\n",
    "    ylabel=\"$<E>(T)$ [J]\",\n",
    "    xticks=T_interval[::2],\n",
    "    xlim=(0,1000)\n",
    ")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total runtime of all simulations: XXXXXXX, the time from running metropolis\n",
    "\n",
    "The diameter of the polymer follows a similar pattern to the energy of the polymer. A high energy gives a large diameter, which is expected since contact between monomers gives lower energy and a large diameter means that less monomers are in contact with eachother.\n",
    "\n",
    "The diameter is large at high temperatures and decreases until around reaches a certain temperature before it doesn't follow any pattern and becomes more random. This makes sense given that at lower temperatures it is easier for the polymer to get \"stuck\" in a local energy minima and the minima it gets \"stuck\" in is random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting cooling and different temperatures in the same plot \n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "ax1.errorbar(\n",
    "    T_interval,\n",
    "    d_mean,\n",
    "    yerr=d_std,\n",
    "    fmt=\".\",\n",
    "    capsize=3,\n",
    "    label=r\"$<d>(T)$\"\n",
    ")\n",
    "ax1.errorbar(\n",
    "    T_interval,\n",
    "    d_rep_mean,\n",
    "    yerr=d_rep_std,\n",
    "    fmt=\".\",\n",
    "    capsize=3,\n",
    "    label=\"$<d>(T)$ cooling\"\n",
    ")\n",
    "ax1.set(\n",
    "    title=\"Diameter different temperatures, at each temperature and simulating cooling\",\n",
    "    xlabel=\"$T$ [Kelvin]\",\n",
    "    ylabel=\"$<d>(T)$ [unit length]\",\n",
    "    xticks=T_interval[::2],\n",
    "    xlim=(0,1000)\n",
    ")\n",
    "\n",
    "ax2.errorbar(\n",
    "    T_interval,\n",
    "    E_mean,\n",
    "    yerr=E_std,\n",
    "    fmt=\".\",\n",
    "    capsize=3,\n",
    "    label=r\"$<E>(T)$\"\n",
    ")\n",
    "\n",
    "ax2.errorbar(\n",
    "    T_interval,\n",
    "    E_rep_mean,\n",
    "    yerr=E_rep_std,\n",
    "    fmt=\".\",\n",
    "    capsize=3,\n",
    "    label=\"$<E>(T)$ cooling\"\n",
    ")\n",
    "\n",
    "ax2.set(\n",
    "    title=\"Energy different temperatures, at each temperature and simulating cooling\",\n",
    "    xlabel=\"$T$ [K]\",\n",
    "    ylabel=\"$<E>(T)$ [J]\",\n",
    "    xticks=T_interval[::2],\n",
    "    xlim=(0,1000)\n",
    ")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polymer that undergoes cooling ends up having an almost constant diameter for the lowest temperatures.  \n",
    "This can be seen by there being very little standard deviation. This is reasonable since the polymer most likely has hit an energy minima before it reaches the lowest temperatures, therefore it will not rotate at all since the energy already is minimized. \n",
    "\n",
    "To see the behavior of the polymer at low temperatures, the process of cooling would be best to simulate a polymer that is created at a higher temperature and then cooled down.\n",
    "If one wants to see what the behaviour of a polymer that is created at an already low temperature, the method of creating a flat polymer for every temperature would be best, since it does not enter the low temperatures with an already established energy minima. \n",
    "\n",
    "At high temperatures the polymer will be very unstable, and both methods should be good since they both give variation in energy and diameter, which the plot shows. They both have high standard deviations and the averages are rather similar for higher temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Conclusion\n",
    "\n",
    "By using Monte Carlo simulation of polymer folding we have arrived at the conclusion that there is a clear relationship \n",
    "between temperature, \n",
    "energy, and the polymer diameter.\n",
    "If starting at low temperatures, the energy of the polymer appear random as a consequence of being trapped in \n",
    "local energy minimas. By increasing the temperature, the energy first dips before monotonically increasing with \n",
    "temperature. The dip can be explained by the fact that when increasing the temperature, the polymer gains enough energy to \n",
    "escape the local energy minima it was locked into, and actually finds a minima closer to the global minima.\n",
    "This is supported by starting the simulation at large temperatures and then cooling the polymer, which results in no \n",
    "randomness at low temperatures.\n",
    "The diameter's dependence on temperature closely mimics that of the energy, indicating that they are strongly connected.\n",
    "Simulating polymer folding has also posed a challenge when it comes to the use of processing power.\n",
    "Utilizing *Numba* and *NumPy* has made the code substantially quicker, \n",
    "enabling us to use bigger and better simulations without taking too much time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- **Define the diameter $d$**\n",
    "- **gj√∏re alle TODOs**\n",
    "- **dobbeltsjekke (og trippeltsjekke) at funksjonene som ligger i notebooken er riktige.**\n",
    "- **sjekke spr√•k og kommentarer i koden**\n",
    "- **sjekke spr√•k i teksten**\n",
    "- **hand in this notebook lol**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1)\n",
    "\n",
    "A closer look at `calulate_energy`'s use of *NumPy*-arrays:\n",
    "\n",
    "```python\n",
    "def calculate_energy(polymer: np.ndarray, V: np.ndarray) -> float:\n",
    "    \"\"\"Calculates the energy of the given polymer.\n",
    "    \n",
    "     Args:\n",
    "        polymer: A 2D numpy array with monomer coordinates\n",
    "\n",
    "        V: A matrix with the bonding energies for the monomers of the given polymer.\n",
    "        V[i, j] = V[j, i] = bonidng energy for the bond between monomer number (i+1) and (j+1).\n",
    "\n",
    "    Returns:\n",
    "        The energy of the polymer\"\"\"\n",
    "    N = len(polymer)\n",
    "    L = np.repeat(polymer, N).reshape(2 * N, N)\n",
    "    b = np.where(\n",
    "        ((L[::2] - L[::2].transpose()) ** 2 + (L[1::2] - L[1::2].transpose()) ** 2)\n",
    "        == 1,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    return 0.5 * (np.sum(V * b))\n",
    "```\n",
    "\n",
    "`calculate_energy` first creates a matrix $L$, which after `numpy.repeat().reshape()` will look as follows:\n",
    "\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "  x_1 & x_1 &\\dots  &x_1 \\\\\n",
    "   y_1& y_1 &\\dots  &y_1 \\\\\n",
    "   x_2& x_2 & \\dots &x_2 \\\\\n",
    "   y_2& y_2 &\\dots  &y_2 \\\\\n",
    "   \\vdots& \\vdots & \\ddots &\\vdots \\\\\n",
    "   y_{N-1}& y_{N-1} & \\dots &y_{N-1} \\\\\n",
    "   x_N& x_N & \\dots & x_N\\\\\n",
    "   y_N& y_N & \\dots &y_N \\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This allows us to exploit *NumPy*'s efficient slicing.\n",
    "\n",
    "By slicing $L$ we get these matrices:\n",
    "\n",
    "`L[::2]`:\n",
    "\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "  x_1 & x_1 &\\dots  &x_1 \\\\\n",
    "   x_2& x_2 & \\dots &x_2 \\\\\n",
    "   \\vdots& \\vdots & \\ddots &\\vdots \\\\\n",
    "   x_{N-1}& x_{N-1} & \\dots &x_{N-1} \\\\\n",
    "   x_N& x_N & \\dots & x_N\\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "`L[1::2]`:\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "   y_1& y_1 &\\dots  &y_1 \\\\\n",
    "   y_2& y_2 &\\dots  &y_2 \\\\\n",
    "   \\vdots& \\vdots & \\ddots &\\vdots \\\\\n",
    "   y_{N-1}& y_{N-1} & \\dots &y_{N-1} \\\\\n",
    "   y_N& y_N & \\dots &y_N \\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "`L[::2].transpose()`:\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "    x_1 & x_2 &\\dots  &x_{N-1} &x_N \\\\\n",
    "   x_1& x_2 & \\dots &x_{N-1}&x_N \\\\\n",
    "   \\vdots& \\vdots & \\ddots & \\vdots&\\vdots \\\\\n",
    "   x_1& x_2 & \\dots &x_{N-1}&x_N \\\\\n",
    "   x_1& x_2 & \\dots &x_{N-1}& x_N\\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "`L[1::2].transpose()`:\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "    y_1 & y_2 &\\dots  &y_{N-1} &y_N \\\\\n",
    "   y_1& y_2 & \\dots &y_{N-1}&y_N \\\\\n",
    "   \\vdots& \\vdots & \\ddots & \\vdots&\\vdots \\\\\n",
    "   y_1& y_2 & \\dots &y_{N-1}&y_N \\\\\n",
    "   y_1& y_2 & \\dots &y_{N-1}& y_N\\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "We now see that the following equation yields a matrix $b$ where the $b_{mn}$ is the euclidian distance between monomer $m$ and $n$.\n",
    "```python\n",
    "((L[::2] - L[::2].transpose()) ** 2 + (L[1::2] - L[1::2].transpose()) ** 2)\n",
    "```\n",
    "\n",
    "Comparing $b_{mn}$ with $1$ in `numpy.where()` yields $b$ where\n",
    "\n",
    "\\begin{equation}\n",
    " b_{mn} =\n",
    "  \\begin{cases}\n",
    "  1 & m \\text{ and } n \\text{ closest neighbours} \\\\\n",
    "  0 & \\text{otherwise} \n",
    "  \\end{cases}\n",
    "\\end{equation}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
